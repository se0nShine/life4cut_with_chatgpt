{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzRKNe1iSlNW"
      },
      "source": [
        "# Google Colab: Access Webcam for Images and Video\n",
        "This notebook will go through how to access and run code on images and video taken using your webcam.  \n",
        "\n",
        "For this purpose of this tutorial we will be using OpenCV's Haar Cascade to do face detection on our Webcam image and video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fj9YcAnsT4B_"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6pCmkJrUC9g"
      },
      "source": [
        "## Helper Functions\n",
        "Below are a few helper function to make converting between different image data types and formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "09b_0FAnUa9y"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZIOR4WaT64"
      },
      "source": [
        "## Haar Cascade Classifier\n",
        "For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZpA68lTrcvZs"
      },
      "outputs": [],
      "source": [
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRFoJo6QT94w"
      },
      "source": [
        "## Webcam Images\n",
        "Running code on images taken from webcam is fairly straight-forward. We will utilize code within Google Colab's **Code Snippets** that has a variety of useful code functions to perform various tasks.\n",
        "\n",
        "We will be using the code snippet for **Camera Capture** to utilize your computer's webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XwUtEojjnPRb"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  # # get face bounding box coordinates using Haar Cascade\n",
        "  # faces = face_cascade.detectMultiScale(gray)\n",
        "  # # draw face bounding box on image\n",
        "  # for (x,y,w,h) in faces:\n",
        "  #     img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qy3DKuU0PWTQ"
      },
      "outputs": [],
      "source": [
        "count = 4\n",
        "images = []\n",
        "\n",
        "def capture_images(cnt):\n",
        "    try:\n",
        "        filename, img = take_photo(f'photo_{cnt}.jpg')\n",
        "        print('Saved to {}'.format(filename))\n",
        "\n",
        "        # Show the image which was just taken.\n",
        "        display(Image(filename))\n",
        "        return img\n",
        "    except Exception as err:\n",
        "        # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "        # grant the page permission to access it.\n",
        "        print(str(err))\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rskL_Qh4TTXL"
      },
      "outputs": [],
      "source": [
        "def save_combine_images_vertically(images, padding=10, gap=10):\n",
        "    if len(images) != 4:\n",
        "        print(\"이미지가 4장이 아닙니다.\")\n",
        "        return None\n",
        "    # 각 이미지의 크기를 구합니다\n",
        "    height,  width, _ = images[0].shape\n",
        "\n",
        "    # 패딩이 적용된 이미지 크기\n",
        "    padded_height = height + 2 * padding\n",
        "    padded_width = width + 2 * padding\n",
        "\n",
        "    # 세로로 결합할 때 전체 높이를 계산합니다 (간격 포함)\n",
        "    combined_height = padded_height * 4 + gap * 3\n",
        "\n",
        "    # 빈 이미지(검은색 배경)를 만듭니다\n",
        "    combined_image = np.zeros((combined_height, padded_width, 3), dtype=np.uint8)\n",
        "\n",
        "    # 이미지를 배치할 때 패딩과 간격을 적용합니다\n",
        "    for i in range(4):\n",
        "        y_offset = i * (padded_height + gap)\n",
        "        combined_image[y_offset + padding:y_offset + padding + height, padding:padding + width] = images[i]\n",
        "\n",
        "    cv2.imwrite('/content/combine_images_vertically.jpg', combined_image)\n",
        "    print('성공적으로 이미지를 저장했습니다!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 네컷 촬영 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "taMKGCE2PWTR"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    for i in range(1, 5):\n",
        "        img = capture_images(i)\n",
        "        images.append(img)\n",
        "    # print(f'images : {images}')\n",
        "    if len(images) == 4:\n",
        "        save_combine_images_vertically(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOxKqcg5Th31"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_modify_image(file_path):\n",
        "    # 이미지 파일을 불러옵니다\n",
        "    combined_image = cv2.imread(file_path)\n",
        "\n",
        "    if combined_image is None:\n",
        "        print(f\"{file_path} 파일을 읽을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 검정색 배경을 흰색으로 변경합니다\n",
        "    combined_image[np.where((combined_image == [0,0,0]).all(axis=2))] = [255, 255, 255]\n",
        "\n",
        "    return combined_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    # 저장된 결합된 이미지 파일 경로\n",
        "    file_path = '/content/combine_images_vertically.jpg'\n",
        "\n",
        "    # 이미지를 불러와서 수정합니다\n",
        "    modified_image = load_and_modify_image(file_path)\n",
        "\n",
        "    if modified_image is not None:\n",
        "        # 수정된 이미지를 저장합니다 (예를 들어, 'modified_image.jpg'로 저장)\n",
        "        cv2.imwrite('/content/modified_background.jpg', modified_image)\n",
        "        print(\"수정된 이미지를 'modified_image.jpg'로 저장했습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 흑백 사진으로 변형하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_modify_image(file_path):\n",
        "    # 이미지 파일을 불러옵니다\n",
        "    combined_image = cv2.imread(file_path)\n",
        "\n",
        "    if combined_image is None:\n",
        "        print(f\"{file_path} 파일을 읽을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 검정색 배경을 흰색으로 변경합니다\n",
        "    combined_image[np.where((combined_image == [0,0,0]).all(axis=2))] = [255, 255, 255]\n",
        "\n",
        "    # 이미지를 흑백으로 변환합니다\n",
        "    gray_image = cv2.cvtColor(combined_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return gray_image\n",
        "\n",
        "def main():\n",
        "    # 저장된 결합된 이미지 파일 경로\n",
        "    file_path = '/content/combine_images_vertically.jpg'\n",
        "\n",
        "    # 이미지를 불러와서 수정합니다\n",
        "    gray_image = load_and_modify_image(file_path)\n",
        "\n",
        "    if gray_image is not None:\n",
        "        # 수정된 이미지를 저장합니다 (예를 들어, 'modified_image.jpg'로 저장)\n",
        "        cv2.imwrite('/content/modified_gray_image.jpg', gray_image)\n",
        "        print(\"수정된 이미지를 'modified_gray_image.jpg'로 저장했습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 이미지에 텍스트 추가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_modify_image(file_path):\n",
        "    # 이미지 파일을 불러옵니다\n",
        "    combined_image = cv2.imread(file_path)\n",
        "\n",
        "    if combined_image is None:\n",
        "        print(f\"{file_path} 파일을 읽을 수 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # 검정색 배경을 흰색으로 변경합니다\n",
        "    combined_image[np.where((combined_image == [0,0,0]).all(axis=2))] = [255, 255, 255]\n",
        "\n",
        "    # 이미지에 텍스트를 추가합니다\n",
        "    text = \"Hello, OpenCV!\"\n",
        "    org = (50, 50)  # 텍스트의 좌측 상단 시작 위치\n",
        "    fontFace = cv2.FONT_HERSHEY_SIMPLEX  # 폰트 선택\n",
        "    fontScale = 1  # 폰트 크기\n",
        "    color = (255, 0, 0)  # 텍스트 색상 (BGR 형식)\n",
        "    thickness = 2  # 선 두께\n",
        "\n",
        "    combined_image = cv2.putText(combined_image, text, org, fontFace, fontScale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "    return combined_image\n",
        "\n",
        "def main():\n",
        "    # 저장된 결합된 이미지 파일 경로\n",
        "    file_path = '/content/combine_images_vertically.jpg'\n",
        "\n",
        "    # 이미지를 불러와서 수정합니다\n",
        "    combined_image = load_and_modify_image(file_path)\n",
        "\n",
        "    if combined_image is not None:\n",
        "        # 수정된 이미지를 저장합니다 (예를 들어, 'modified_image.jpg'로 저장)\n",
        "        cv2.imwrite('/content/modified_text_image.jpg', combined_image)\n",
        "        print(\"텍스트가 추가된 이미지를 'modified_text_image.jpg'로 저장했습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
